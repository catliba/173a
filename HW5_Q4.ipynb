{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HW 5 question 3\n",
    "# implement gradient descent here using back tracking\n",
    "\n",
    "w = np.zeros((784,1))\n",
    "\n",
    "def gradF(w, x_train, y_train):\n",
    "    z = np.dot(x_train, w)\n",
    "    sigmoid = 1/(1+np.exp(-z))\n",
    "    grad = np.dot(x_train.T,(sigmoid - (y_train==1))) / x_train.shape[0]\n",
    "    return grad\n",
    "\n",
    "def F(w, x_train, y_train):\n",
    "    z = np.dot(x_train, w)\n",
    "    F = np.log(1+np.exp(-y_train*z))\n",
    "    F = np.clip(F, a_min = None, a_max = 500)\n",
    "    return np.mean(F)\n",
    "\n",
    "def backtrack(F, w, x_train, y_train, grad):\n",
    "    gamma = 0.5\n",
    "    beta = 0.8\n",
    "    mu = 0.1 #10^-1 = 0.1\n",
    "    while F(w - mu  * grad, x_train, y_train) > F(w, x_train, y_train) - mu * gamma * np.linalg.norm(grad)**2:\n",
    "        #print(\"Fx: \", F(w - mu * grad, x_train, y_train),\"Fy: \", F(w, x_train, y_train) - mu * gamma * np.linalg.norm(grad)**2 )\n",
    "        mu = beta * mu      \n",
    "    #print(\"mu value\", mu)\n",
    "    return mu\n",
    "    \n",
    "def gradient_descent(w, T=10, mu=1e-2, num1=4, num2=9, plot=True):\n",
    "    x_train, y_train, x_test, y_test = output_data(num1, num2)\n",
    "    F_history = []\n",
    "    for t in range(T):\n",
    "        F_history.append(F(w,x_train, y_train))\n",
    "        gradient = gradF(w,x_train, y_train)\n",
    "        mu1 = backtrack(F, w, x_train, y_train, gradient)\n",
    "        w = w-mu1*gradient\n",
    "        \n",
    "        if(t%500) == 0:\n",
    "            print('Finished', t, 'iterations...')\n",
    "            clear_output(wait=True)\n",
    "         \n",
    "    if plot:\n",
    "        plt.plot(range(T), F_history)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Training Error')\n",
    "        plt.title('GD Loss using backtracking for '+str(num1)+ '&'+str(num2))\n",
    "\n",
    "    return w, F_history, x_train, y_train, x_test, y_test\n",
    "\n",
    "# Call gradient_descent for digits 4 and 9\n",
    "Tmax = 10000\n",
    "w_star, F_hist, x_train, y_train, x_test, y_test = gradient_descent(w, T=Tmax, mu=1e-4, num1=4, num2=9, plot=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
